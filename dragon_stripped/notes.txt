# Changes from Original Implementation

The original implementation was pretty broken and basically didn't execute as is. From what I understand,
the AI benchmarks were probably (?) better maintained and support for the non-AI benchmarks were in a state of disrepair. 

I didn't change too much of the basic logical functionality, so if the logic (cycle / load / store / memory calculations) is incorrect, this should be changed. I made changes to (1) improve readability / maintainability (2) ensure the mapping procedure executes with no user intervention:

- added instrumentation / execution pass (`hls_instrument`) to obtain variable sizes and loop iteration counts for variables and loop locations. Note that this is really imprecise and doesn't handle scoping at the moment. This was previously done through hacks basically -- users would manually provide max number of iterations for non-`range(#)` for statements. This pass operates by instrumenting all loops and assignments (logging sizes + counts) and then executing the augmented benchmark file (tmp.py) and parsing the log file (log.txt).

	- The analysis conservatively takes the largest declared size for each variable. Each variable is referenced by its name in the source file.

	- The analysis assumes loops with a single iteration counts are fixed and unrolls them complete, and assumes loops with multiple distinct iteration counts are variable and only unrolls once. You probably want smarter loop unrolling code. This was previously left mostly up to the user. 

- Added HwModel and ExecutionBlock Classes for keeping track of execution statistics. Execution blocks which capture the memory/compute/hardware count statistics of individual statements, are added to the hardware model as statements are processed. The HwModel maintains a list of ExecutionBlocks, and computes the final cycle counts and hardware counts from it. Before, this was done by modifying globals in functions -- all the logic was intermixed in the analysis, so it was hard to tell what was going on.

- Now, the HLS procedure works directly on the CFG and maps python ast.AST nodes to hardware elements. Before, the code serialized the AST into a python source string, and then re-parsed it with a regex to get operator counts.

- All of the AST convenience functions have been factored out and relocated to `ast_utils.py` for convenience. This is to separate the mapping logic from the AST manipulation code.

- I render the CFG to `spmv` and `spmv.pdf` now. 


#### What Stayed the Same?

- I did not modify `cfg_builder.py` and `cfg_model.py`. These files construct a CFG from a source file

- I did not really change the bookkeeping (the HWModel, ExecutionBlock dictionaries). There is definitely a better way to do this.

# Postmortem

The following section outlines how i derived the stripped down implementation.

### core file

`src/synthesis/hls.py`

_Functions of interest:_ parse_graph, check_and_parse, parse_code

This is the starting file. Note this file is extremely broken and will not run
as-is.


### calling files (parse_graph)

Next, i traced the functions in `hls.py` to find the calling files.

`src/ir/ddfg_main.py`

The above file invokes the `parse_graph` hls function. This file appears to run the main optimization loop. I broke out the `synthesis_hardware` function that parses programs and then produces program statistics from these parsed programs. The `synthesis_hardware` subroutine uses two different flows:


- It uses `aladdin` (CPP+Boost) for ai workloads [ignoring]. I am not looking at this one for now, since we are interested in non-AI workloads.

- The ``CFGBuilder` class in `builder.py` and `model.py` in `src/ir/cfg/staticcfg/*` is invoked to build the relevent graph representation. This routine uses `astor` to assist with building the relevent data structures for  non-ai workloads.
	+ `Astor`: astor is designed to allow easy manipulation of Python source via the AST. (https://pypi.org/project/astor/)
	
### Toplevel

The `run.ipynb` notebook is the best toplevel notebook.

# Guide: Stripped Parser

you want to pay attention to the `nonai` benchmark usecase. Basically the `synthesis_nonai_hardware` routine use CFGBuilder to produce a control flow graph of the given program, and then uses HLS to produce the mapped computation.

